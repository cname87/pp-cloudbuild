## Continuous Integration & Continuous Delivery cloud build ##

# The cloud build is triggered by a commit to the master branch of the project-perform-k8es repo.  It downloads secrets that are not stored on the git repo, installs and builds the frontend and backend applications, units tests them, and then builds the frontend and backend images and pushes them to the cloud registry.

## Cloud Build explanation...
# 1. It copies the source project files & directories, excluding those directories listed in .gcloudignore.  (Note that when running gcloud locally it appears to ignore .gcloudignore).
# NOTE: It copies from the current working directory. Therefore run any calling script from the project root as all the steps assume the project root is the cwd.
# 2. Each step builds an image and runs an associated container with the copied source files mounted at /workspace.
# Changes made to the /workspace directory are persisted between each build step.
# Note: Define the working directory of the container in each step using a relative path, which will be relative to /workspace, i.e. relative to the project source files. (The absolute path '/' would make the working directory be the root of the container which is typically not what you want).

# To run...
# A build is triggered by a check in to the master branch on the repo (if so configured).
# Run 'gcloud builds submit --config cloudbuild.yaml .' from the project root to trigger a cloud build.
# Run 'cloud-build-local --dryrun=false .' to trigger a local build.


steps:

# Print out local variables
- id: 'Print variables'
  name: gcr.io/cloud-builders/gcloud
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    echo 'The BUILD_TAG informs whether the build was local or on GCP'
    echo 'BUILD_TAG: $_BUILD_TAG'
    echo 'PROJECT_ID: $PROJECT_ID'
    echo 'BUILD_ID: $BUILD_ID'
    echo 'COMMIT_SHA: $COMMIT_SHA'
    echo 'SHORT_SHA: $SHORT_SHA'
    echo 'COMMIT_SHA: $COMMIT_SHA'
    echo 'Images may be from the test or production registries'
    echo 'BACKEND_IMAGE: $_BACKEND_IMAGE'
    echo 'FRONTEND_IMAGE: $_FRONTEND_IMAGE'
    echo 'Versions may be a commit short SHA or a test tag'
    echo 'BACKEND_VERSION: $_BACKEND_VERSION'
    echo 'FRONTEND_VERSION: $_FRONTEND_VERSION'

# When a build is executed from GCP via a github trigger, the secret files and associated directories are not in git so you must download them from GCP Storage.  The directory structure of the GCP storage bucket MUST be set up to match the directory structure of the missing files & directories, as a recursive copy is carried out to copy the directory structure and files.
# Note: This step is superfluous when triggered via CLI.

# # Copy the backend .env, frontend e2e .env, database certs, & GCP Storage key files from GCP Storage to the persisted workspace
# - id: 'download environment and certs files'
#   name: 'gcr.io/cloud-builders/gsutil'
#   dir: '.'
#   args: [
#     # Run operations in parallel
#     '-m',
#     # Copy recursively
#     'cp', '-r',
#     # Don't overwrite
#     '-n',
#     'gs://project-perform-gcp-environment-files/*',
#     '.',
#   ]

# # Create a bucket to hold the released secrets
# # Skip if the bucket creation fails because it already exists
# - id: 'create release folder for secrets'
#   name: 'gcr.io/cloud-builders/gsutil'
#   entrypoint: 'sh'
#   dir: '.'
#   args:
#   - '-c'
#   - |
#     gsutil mb 'gs://project-perform-release-${_SHORT_SHA}' || echo "Secrets release folder already exists"

# # Copy the secret files to the release storage bucket
# - id: 'copy secrets to release folder'
#   name: 'gcr.io/cloud-builders/gsutil'
#   dir: '.'
#   args: [
#     # Run operations in parallel
#     '-m',
#     # Copy recursively
#     'cp', '-r',
#     'gs://project-perform-gcp-environment-files/*',
#     'gs://project-perform-release-${_SHORT_SHA}',
#   ]

# Install the backend node_modules directory in the persisted workspace
# Note: Using the node-with-puppeteer image (rather than a simple node image) as it is needed in other steps (which means only 1 image download) is required
- id: 'install backend node_modules'
  name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
  entrypoint: npm
  dir: './backend'
  args: ['install']

# Install the frontend node_modules directory in the persisted workspace
- id: 'install frontend node_modules'
  name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
  entrypoint: npm
  dir: './frontend'
  args: ['install']

# # Build the backend in the persisted workspace in the dist directory.  The newly built dist files are later deployed.
# - id: 'build backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './backend'
#   args: ['run', 'build']

# # Build the frontend in the persisted workspace in the dist directory.  The newly built dist files are later deployed.
# - id: 'build frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './frontend'
#   args: ['run', 'build:prod']

# # Run all backend unit tests
# # Must have Node & Puppeteer in the base image
# - id: 'unit test backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './backend'
#   env: ['NODE_ENV=staging']
#   args: ['npm', 'run', 'test']

# # Run all frontend unit tests.
# # Must have Node & Puppeteer in the base image
# - id: 'unit test frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'test:staging']

# Build the backend server image (which is later deployed)
- id: 'Build backend server image'
  name: 'gcr.io/cloud-builders/docker'
  dir: './backend'
  args: [
    'build',
    '--file=Dockerfile',
    '--tag=${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
    '.']

# Push the backend server image so it can be pulled for deployment
- id: 'Push backend server image'
  name: 'gcr.io/cloud-builders/docker'
  args: [
    'push',
    '${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
  ]

# Build the frontend server image (which is later deployed)
- id: 'Build frontend server image'
  name: 'gcr.io/cloud-builders/docker'
  dir: './frontend'
  args: [
    'build',
    '--file=Dockerfile',
    '--tag=${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
    '.',
  ]

# Push the frontend server image so it can be pulled for deployment
- id: 'Push frontend server image'
  name: 'gcr.io/cloud-builders/docker'
  args: [
    'push',
    '${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
  ]

# # Run the backend server in the background (for e2e test)
# - id: 'Run backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'run',
#     # The name matches the proxy url set up in the e2e configuration.
#     '--name=backend',
#     # Remove container when stopped.
#     '--rm',
#     # Run detached.
#     '-d=true',
#     # Expose port on backend (8080)
#     '-p=8080:8080',
#     # Attach to the local Docker network named cloudbuild to which the container in each build step is attached.
#     '--network=cloudbuild',
#     # Run with NODE_ENV=staging => TEST_PATHS available.
#     '--env', 'NODE_ENV=staging',
#     # Runs the image built in a previous build step.
#     '${_BACKEND_IMAGE}:${_BACKEND_VERSION}'
#   ]

# # Runs an e2e test against the built backend server.
# # Runs a local frontend server serving the built frontend.
# # Pre-compiles the frontend using a staging environment file that enables error and cache interceptors in the frontend.
# # Runs Protractor using a staging configuration that runs the cache or errors tests.
# # BASE_URL is set to run against the server running in the backend.
# # The configured test user has access to the test database.
# # The staging environment file selected by NODE_ENV=staging sets the backend server to be run with test paths available.  It also sets that the test database is in use.
# - id: 'Run e2e test in staging environment'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'e2e:staging']

# # Stops the backend server running in the background, (and it is removed automatically).
# - id: 'Stop backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'container',
#     'stop',
#     'backend',
#   ]

# # Runs e2e test against the newly deployed build.
# # Does not pre-compile or run a local frontend server so it uses the frontend production build in the production server which does not enable error and cache interceptors in the frontend.
# # Runs Protractor using a production staging configuration that does not run the cache or errors tests.
# # BASE_URL is set to run against the production cluster.
# # The configured test user has access to the production database, (to a 'test' collection).
# # The production cluster runs with an environment file selected by NODE_ENV=production which sets the backend server to be run with no test paths available.  It also sets that the production database is in use.
# - id: 'e2e test the production deployment'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: 'sh'
#   dir: './frontend'
#   args:
#   - '-c'
#   - |
#     test "${_GKE_CLUSTER}" = "ppk8es-cluster-prod" && \
#     npm run e2e:production || echo "Skipped final e2e:production step as not a production build"

substitutions:
  # These are default values which are set to match a production build run from GCP. These are overwritten from the runbuild.sh utility to run a test build.  They can also be overwritten when a build is triggered by Git but there is less need as the default values are set up for a production build.
  # PROJECT_ID: Cloud Build defaults to the ID of your Cloud project.
  # BUILD_ID: Cloud Build defaults to the ID of your build.
  # COMMIT_SHA: Cloud Build sets this to the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually.
  # SHORT_SHA: Cloud Build sets this to the first 7 characters of the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually.
  _SHORT_SHA: ${SHORT_SHA}
  # Set the default cluster for the git triggered case - normally set to the production cluster but can be set to the test cluster if I am only working with one cluster.
  _GKE_REGION: europe-west2
  _GKE_ZONE: europe-west2-c
  # Use production directory for the images
  _BACKEND_IMAGE: 'gcr.io/project-perform/pp-backend-cb/production'
  _FRONTEND_IMAGE: 'gcr.io/project-perform/pp-frontend-cb/production'
  # When triggered from git, the images are tagged with the git short commit hash - this is overridden when calling locally.
  _BACKEND_VERSION: '${SHORT_SHA}'
  _FRONTEND_VERSION: '${SHORT_SHA}'
  # Overwritten to 'ppk8es_triggered' in the git trigger.
  _BUILD_TAG: 'ppk8es'

options:
    substitution_option: 'ALLOW_LOOSE'

tags: [$_BUILD_TAG]

timeout: 1800s
