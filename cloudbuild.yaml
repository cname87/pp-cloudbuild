# Cloud Build...
# 1. Copies the source project files & directories, excluding those directories listed in .gcloudignore.  (Note that when running gcloud locally it appears to ignore .gcloudignore).
# 2. Each step builds an image and runs an associated container with the copied source files mounted at /workspace.
# Changes made to the /workspace directory are persisted between each build step.
# Note: Define the working directory of the container in each step using a relative path, which will be relative to /workspace, i.e. relative to the project source files. (If you define an absolute path, e.g. 'dir: /' the working directory would be the root of the container which is typically not what you want).

# To run...
# Run 'gcloud builds submit --config cloudbuild.yaml .' from the project root to trigger a cloud build.
# Run 'cloud-build-local --dryrun=false .' to trigger a local build.
# A build can also be triggered by a change in a github repo (if so configured).

steps:

# # # When a build is executed from GCP via a github trigger the secret files, and associated directories, are not in git so you must download them from GCP Storage.  The directory structure of the GCP storage bucket MUST be set up to match the directory structure of the missing files & directories, as a recursive copy is carried out to copy the directory structure and files.
# # # Note: This step is superfluous when triggered via CLI.

# # Copy the backend .env, frontend e2e .env, database certs, & GCP Storage key files from GCP Storage to the persisted workspace.
# - id: 'download environment and certs files'
#   name: 'gcr.io/cloud-builders/gsutil'
#   dir: '.'
#   args: [
#     # Run operations in parallel
#     '-m',
#     # Copy recursively
#     'cp', '-r',
#     # Don't overwrite
#     '-n',
#     'gs://project-perform-gcp-environment-files/*',
#     '.',
#   ]

# # Install the backend node_modules directory in the persisted workspace.
# # Note: Using the node-with-puppeteer image (rather than a simple node image) as it is needed in other steps (which means only 1 image download) is required.
# - id: 'install backend node_modules'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './backend'
#   args: ['install']

# # Install the backend node_modules directory in the persisted workspace.
# - id: 'install frontend node_modules'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './frontend'
#   args: ['install']

# # Build the backend in the persisted workspace (replacing the copied in dist files - the newly built files are later deployed).
# - id: 'build backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './backend'
#   args: ['run', 'build']

# # Build the frontend in the persisted workspace (replacing the copied-in dist files - the newly built files are later deployed).
# - id: 'build frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './frontend'
#   args: ['run', 'build:prod']

# # Run all backend unit tests.
# # Must have Node & Puppeteer in the base image.
# - id: 'unit test backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './backend'
#   env: ['NODE_ENV=staging']
#   args: ['npm', 'run', 'test']

# # Run all frontend unit tests.
# # Must have Node & Puppeteer in the base image.
# - id: 'unit test frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'test:staging']

# # Build the backend server image (which is later deployed).
# - id: 'Build backend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'build',
#     '--file=Dockerfile',
#     '--tag=${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
#     '.']

# # Push the backend server image so it can be pulled for deployment.
# - id: 'Push backend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   args: [
#     'push',
#     '${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
#   ]

# # Build the frontend server image (which is later deployed).
# - id: 'Build frontend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './frontend'
#   args: [
#     'build',
#     '--file=Dockerfile',
#     '--tag=${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
#     '.',
#   ]

# # Push the backend server image so it can be pulled for deployment.
# - id: 'Push frontend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   args: [
#     'push',
#     '${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
#   ]

# # Run the backend server in the background.
# - id: 'Run backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'run',
#     # The name matches the proxy url set up in the e2e configuration.
#     '--name=backend',
#     # Remove container when stopped.
#     '--rm',
#     # Run detached.
#     '-d=true',
#     # Expose port on backend (8080)
#     '-p=8080:8080',
#     # Attach to the local Docker network named cloudbuild to which the container in each build step is attached.
#     '--network=cloudbuild',
#     # Run with NODE_ENV=staging => TEST_PATHS available.
#     '--env', 'NODE_ENV=staging',
#     # Runs the image built in a previous build step.
#     '${_BACKEND_IMAGE}:${_BACKEND_VERSION}'
#   ]

# # Runs an e2e test against the built backend server.
# # Runs a local frontend server serving the built frontend.
# # Pre-compiles the frontend using a staging environment file that enables error and cache interceptors in the frontend.
# # Runs Protractor using a staging configuration that runs the cache or errors tests.
# # BASE_URL is set to run against the server running in the backend.
# # The configured test user has access to the test database.
# # The staging environment file selected by NODE_ENV=staging sets the backend server to be run with test paths available.  It also sets that the test database is in use.
# - id: 'Run e2e test in staging environment'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'e2e:staging']

# # Stops the backend server running in the background, (and it is removed automatically).
# - id: 'Stop backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'container',
#     'stop',
#     'backend',
#   ]

# 'Get private ssh key from Google Secret Manager to allow push access to Github'
- id: 'Get github access'
  name: gcr.io/cloud-builders/gcloud
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    set -x && \
    gcloud secrets versions access latest --secret=id_github > /root/.ssh/id_github
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# Add github.com public key to known_hosts - allows client to authenticate github.com is indeed github.com
- id: 'Set up github access'
  name: 'gcr.io/cloud-builders/git'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    set -x && \
    chmod 600 /root/.ssh/id_github && \
    cat <<EOF >/root/.ssh/config
    Hostname github.com
    IdentityFile /root/.ssh/id_github
    EOF
    ssh-keyscan -t rsa github.com > /root/.ssh/known_hosts
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# Clone the project Continuous Delivery repository and checkout the candidate branch.
- id: Clone CD repository
  name: 'gcr.io/cloud-builders/git'
  entrypoint: /bin/sh
  dir: '.'
  args:
  - '-c'
  - |
    set -x && \
    git clone git@github.com:cname87/$_CD_REPO && \
    cd  $_CD_REPO  && \
    git checkout candidate
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# 'Copy the local Helm chart to the CD Repo'
- id: 'Copy Helm chart to CD Repo'
  name: gcr.io/cloud-builders/gcloud
  entrypoint: 'bash'
  args:
  -  '-c'
  - |
    set -x && \
    cp -rf ./pp-chart ./$_CD_REPO

# Update the CD Repo Helm chart to refer to the new frontend image
- id: Update frontend image in the Helm chart
  name: gcr.io/$PROJECT_ID/yq
  args:
  - yq
  - write
  - --inplace
  - $_CD_REPO/pp-chart/values.yaml
  - 'frontend.image'
  - ${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}

# Update the CD Repo Helm chart to refer to the new backend image
- id: Update backend image in the Helm chart
  name: gcr.io/$PROJECT_ID/yq
  args:
  - yq
  - write
  - --inplace
  - $_CD_REPO/pp-chart/values.yaml
  - 'backend.image'
  - ${_BACKEND_IMAGE}:${_BACKEND_VERSION}

# 'Cat '
- id: 'Cat'
  name: gcr.io/cloud-builders/gcloud
  entrypoint: 'bash'
  args:
  -  '-c'
  - |
    set -x && \
    cat $_CD_REPO/pp-chart/values.yaml

# Push the updated Helm chart back to the remote CD repo
- name: gcr.io/cloud-builders/git
  id: Push edited chart back to the CD repo
  entrypoint: /bin/sh
  dir: '.'
  args:
  - '-c'
  - |
    set -x && \
    cd $_CD_REPO && \
    git config user.email $(gcloud auth list --filter=status:ACTIVE --format='value(account)') && \
    git add . && \
    git commit -m "Deploys image ${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}
    Built from commit ${COMMIT_SHA} of repository project-perform-k8es
    Author: $(git log --format='%an <%ae>' -n 1 HEAD)" && \
    git push git@github.com:cname87/project-perform-k8es-cd candidate
  volumes:
  - name: 'ssh'
    path: /root/.ssh

substitutions: # default values
  # PROJECT_ID: Cloud Build defaults to the ID of your Cloud project
  # BUILD_ID: Cloud Build defaults to the ID of your build
  # COMMIT_SHA: Cloud Build sets this to the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually
  # SHORT_SHA: Cloud Build sets this to the first 7 characters of the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually
  # TAG_NAME: Cloud Build sets this to the tag of the git commit that triggered this cloud build run, or to '' if cloud build is run manually
  _BACKEND_IMAGE: 'pp-backend'
  _FRONTEND_IMAGE: 'pp-frontend'
  _BACKEND_VERSION: '${TAG_NAME}:${SHORT_SHA}'
  _FRONTEND_VERSION: '${TAG_NAME}:${SHORT_SHA}'
  _CD_REPO: 'project-perform-pp-chart-k8es-cd'

  _BUILD_TAG: 'ppk8es-CI'

options:
    substitution_option: 'ALLOW_LOOSE'

tags: [$_BUILD_TAG]

timeout: 1800s
