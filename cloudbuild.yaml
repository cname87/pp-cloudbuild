## Continuous Integration cloud build ##

# The CI cloud build is triggered by a commit to the master branch of the project-perform-k8es CI repo.  It units tests and builds the frontend and backend images and pushes them to the cloud registry.  It e2e tests the built images.  It clones the CD repo and copies the Helm chart to be deployed to the candidate branch of the CD repo.  It edits the Helm in the cloned repo to point to the new images.  Finally it commits and pushes the edited candidate branch back to the remote CD repo.

## Cloud Build explanation...
# 1. Copies the source project files & directories, excluding those directories listed in .gcloudignore.  (Note that when running gcloud locally it appears to ignore .gcloudignore).
# 2. Each step builds an image and runs an associated container with the copied source files mounted at /workspace.
# Changes made to the /workspace directory are persisted between each build step.
# Note: Define the working directory of the container in each step using a relative path, which will be relative to /workspace, i.e. relative to the project source files. (If you define an absolute path, e.g. 'dir: /' the working directory would be the root of the container which is typically not what you want).

# To run...
# Run 'gcloud builds submit --config cloudbuild.yaml .' from the project root to trigger a cloud build.
# Run 'cloud-build-local --dryrun=false .' to trigger a local build.
# A build can also be triggered by a change in a github repo (if so configured).

steps:

# When a build is executed from GCP via a github trigger the secret files, and associated directories, are not in git so you must download them from GCP Storage.  The directory structure of the GCP storage bucket MUST be set up to match the directory structure of the missing files & directories, as a recursive copy is carried out to copy the directory structure and files.
# Note: This step is superfluous when triggered via CLI.

# # Copy the backend .env, frontend e2e .env, database certs, & GCP Storage key files from GCP Storage to the persisted workspace
# - id: 'download environment and certs files'
#   name: 'gcr.io/cloud-builders/gsutil'
#   dir: '.'
#   args: [
#     # Run operations in parallel
#     '-m',
#     # Copy recursively
#     'cp', '-r',
#     # Don't overwrite
#     '-n',
#     'gs://project-perform-gcp-environment-files/*',
#     '.',
#   ]

# # Install the backend node_modules directory in the persisted workspace
# # Note: Using the node-with-puppeteer image (rather than a simple node image) as it is needed in other steps (which means only 1 image download) is required
# - id: 'install backend node_modules'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './backend'
#   args: ['install']

# # Install the frontend node_modules directory in the persisted workspace
# - id: 'install frontend node_modules'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './frontend'
#   args: ['install']

# # Build the backend in the persisted workspace in the dist directory.  The newly built dist files are later deployed.
# - id: 'build backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './backend'
#   args: ['run', 'build']

# # Build the frontend in the persisted workspace in the dist directory.  The newly built dist files are later deployed.
# - id: 'build frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   entrypoint: npm
#   dir: './frontend'
#   args: ['run', 'build:prod']

# # Run all backend unit tests
# # Must have Node & Puppeteer in the base image
# - id: 'unit test backend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './backend'
#   env: ['NODE_ENV=staging']
#   args: ['npm', 'run', 'test']

# # Run all frontend unit tests.
# # Must have Node & Puppeteer in the base image
# - id: 'unit test frontend'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'test:staging']

# # Build the backend server image (which is later deployed)
# - id: 'Build backend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'build',
#     '--file=Dockerfile',
#     '--tag=${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
#     '.']

# # Push the backend server image so it can be pulled for deployment
# - id: 'Push backend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   args: [
#     'push',
#     '${_BACKEND_IMAGE}:${_BACKEND_VERSION}',
#   ]

# # Build the frontend server image (which is later deployed)
# - id: 'Build frontend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './frontend'
#   args: [
#     'build',
#     '--file=Dockerfile',
#     '--tag=${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
#     '.',
#   ]

# # Push the backend server image so it can be pulled for deployment
# - id: 'Push frontend server image'
#   name: 'gcr.io/cloud-builders/docker'
#   args: [
#     'push',
#     '${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}',
#   ]

# # Run the backend server in the background (for e2e test)
# - id: 'Run backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'run',
#     # The name matches the proxy url set up in the e2e configuration.
#     '--name=backend',
#     # Remove container when stopped.
#     '--rm',
#     # Run detached.
#     '-d=true',
#     # Expose port on backend (8080)
#     '-p=8080:8080',
#     # Attach to the local Docker network named cloudbuild to which the container in each build step is attached.
#     '--network=cloudbuild',
#     # Run with NODE_ENV=staging => TEST_PATHS available.
#     '--env', 'NODE_ENV=staging',
#     # Runs the image built in a previous build step.
#     '${_BACKEND_IMAGE}:${_BACKEND_VERSION}'
#   ]

# Runs an e2e test against the built backend server.
# Runs a local frontend server serving the built frontend.
# Pre-compiles the frontend using a staging environment file that enables error and cache interceptors in the frontend.
# Runs Protractor using a staging configuration that runs the cache or errors tests.
# BASE_URL is set to run against the server running in the backend.
# The configured test user has access to the test database.
# The staging environment file selected by NODE_ENV=staging sets the backend server to be run with test paths available.  It also sets that the test database is in use.
# - id: 'Run e2e test in staging environment'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'e2e:staging']

# # Stops the backend server running in the background, (and it is removed automatically).
# - id: 'Stop backend server'
#   name: 'gcr.io/cloud-builders/docker'
#   dir: './backend'
#   args: [
#     'container',
#     'stop',
#     'backend',
#   ]

# Update the local Helm chart to refer to the new frontend image
- id: Update frontend image in the Helm chart
  name: gcr.io/$PROJECT_ID/yq
  args:
  - yq
  - write
  - --inplace
  - ./pp-chart/values.yaml
  - 'frontend.image'
  - ${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}

# Update the local Helm chart to refer to the new backend image
- id: Update backend image in the Helm chart
  name: gcr.io/$PROJECT_ID/yq
  args:
  - yq
  - write
  - --inplace
  - ./pp-chart/values.yaml
  - 'backend.image'
  - ${_BACKEND_IMAGE}:${_BACKEND_VERSION}

# Get private ssh key from Google Secret Manager to allow push access to Github
- id: 'Get github access'
  name: gcr.io/cloud-builders/gcloud
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    set -x && \
    gcloud secrets versions access latest --secret=id_github > /root/.ssh/id_github
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# Add github.com public key to known_hosts - allows client to authenticate github.com is indeed github.com
- id: 'Set up github access'
  name: 'gcr.io/cloud-builders/git'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    set -x && \
    chmod 600 /root/.ssh/id_github && \
    cat <<EOF >/root/.ssh/config
    Hostname github.com
    IdentityFile /root/.ssh/id_github
    EOF
    ssh-keyscan -t rsa github.com > /root/.ssh/known_hosts
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# Clone the project repository and checkout the candidate branch
- id: Clone repository
  name: 'gcr.io/cloud-builders/git'
  entrypoint: /bin/sh
  dir: '.'
  args:
  - '-c'
  - |
    set -x && \
    git clone --depth 1 --no-single-branch git@github.com:cname87/$_REPO && \
    cd  $_REPO  && \
    git checkout candidate
  volumes:
  - name: 'ssh'
    path: /root/.ssh


# Copy the updated Helm chart to the local candidate branch, commit and push back to the remote repo
# Check out the production branch. (Do this here rather than at the start of a step as it takes time)
- id: Push edited chart back to the candidate branch on the remote repo
  name: gcr.io/cloud-builders/git
  entrypoint: /bin/sh
  dir: '$_REPO'
  args:
  - '-c'
  - |
    set -x && \
    cp -f ../pp-chart/values.yaml ./pp-chart/values.yaml && \
    git config user.email $(gcloud auth list --filter=status:ACTIVE --format='value(account)') && \
    git add . && \
    git commit -m "Deploys image ${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}
    Built from commit ${COMMIT_SHA} of repository $_REPO
    Author: $(git log --format='%an <%ae>' -n 1 HEAD)" && \
    git push git@github.com:cname87/$_REPO candidate && \
    git checkout production
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# Confirm gcloud credentials and cluster access.
- id: Confirm gcloud cluster access
  name: gcr.io/cloud-builders/kubectl
  args:
    - cluster-info
  env:
  - 'CLOUDSDK_COMPUTE_ZONE=$_GKE_ZONE'
  - 'CLOUDSDK_CONTAINER_CLUSTER=$_GKE_CLUSTER'
  - 'KUBECONFIG=~/.kube/config'

# Lint the project Helm chart.
- id: 'Lint Helm chart'
  name: 'gcr.io/$PROJECT_ID/helm'
  dir: '$_REPO'
  args: ['lint', 'pp-chart']
  env:
  - 'CLOUDSDK_COMPUTE_ZONE=$_GKE_ZONE'
  - 'CLOUDSDK_CONTAINER_CLUSTER=$_GKE_CLUSTER'

# Upgrade or install the Helm chart onto the GKE cluster.
- id: 'Upgrade Helm chart on cluster'
  name: 'gcr.io/$PROJECT_ID/helm'
  dir: '$_REPO'
  args: [
    'upgrade',
    '-f', './pp-chart/values.yaml',
    'project-perform',
    './pp-chart',
    '--install',
    '--atomic',
    '--cleanup-on-fail',
  ]
  env:
  - 'CLOUDSDK_COMPUTE_ZONE=$_GKE_ZONE'
  - 'CLOUDSDK_CONTAINER_CLUSTER=$_GKE_CLUSTER'
  - 'KUBECONFIG=~/.kube/config'

# # Runs e2e test against the newly deployed build.
# # Does not pre-compile or run a local frontend server so it uses the frontend production build in the production server which does not enable error and cache interceptors in the frontend.
# # Runs Protractor using a production staging configuration that does not run the cache or errors tests.
# # BASE_URL is set to run against the production cluster.
# # The configured test user has access to the production database, (to a 'test' collection).
# # The production cluster runs with an environment file selected by NODE_ENV=production which sets the backend server to be run with no test paths available.  It also sets that the production database is in use.
# - id: 'e2e test the production deployment'
#   name: 'gcr.io/$PROJECT_ID/node-with-puppeteer'
#   dir: './frontend'
#   args: ['npm', 'run', 'e2e:production'

# This step copies the Helm chart to the production branch and pushes back to remote.  (The production branch is checked out from a previous step)
- id: Push edited chart back to the production branch on the remote repo
  name: gcr.io/cloud-builders/git
  entrypoint: /bin/sh
  dir: '$_REPO'
  args:
  - '-c'
  - |
    set -x && \
    ls && \
    git config user.email $(gcloud auth list --filter=status:ACTIVE --format='value(account)') && \
    # Copy Helm chart to repo in the checked out production branch
    cp -f ../pp-chart/values.yaml ./pp-chart/values.yaml && \
    git add . && \
    git commit -m "Deploys image ${_FRONTEND_IMAGE}:${_FRONTEND_VERSION}
    Built from commit ${COMMIT_SHA} of repository $_REPO
    Author: $(git log --format='%an <%ae>' -n 1 HEAD)" && \
    git push git@github.com:cname87/$_REPO production
  volumes:
  - name: 'ssh'
    path: /root/.ssh

substitutions: # default values - can be overwritten
  # PROJECT_ID: Cloud Build defaults to the ID of your Cloud project
  # BUILD_ID: Cloud Build defaults to the ID of your build
  # COMMIT_SHA: Cloud Build sets this to the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually
  # SHORT_SHA: Cloud Build sets this to the first 7 characters of the git commit hash that triggered this cloud build run, or to '' if cloud build is run manually
  _GKE_CLUSTER: ppk8es-cluster-prod
  _GKE_ZONE: europe-west2-c
  # Use production directory for the images
  _BACKEND_IMAGE: 'gcr.io/project-perform/pp-backend/production'
  _FRONTEND_IMAGE: 'gcr.io/project-perform/pp-frontend/production'
  # The images are tagged with the git short commit hash
  _BACKEND_VERSION: '${SHORT_SHA}'
  _FRONTEND_VERSION: '${SHORT_SHA}'
  # The name of the CD repo (which deploys the Helm chart)
  _REPO: 'project-perform-k8es'
  _BUILD_TAG: 'ppk8es'

options:
    substitution_option: 'ALLOW_LOOSE'

tags: [$_BUILD_TAG]

timeout: 1800s
